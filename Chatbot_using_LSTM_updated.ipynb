{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_using_LSTM_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rachhh53/chatbot/blob/main/Chatbot_using_LSTM_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xoKYBBO6xaV"
      },
      "source": [
        "# **Chatbot using Seq2Seq LSTM models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SOmE99B7Is0"
      },
      "source": [
        "This project is to create conversational chatbot using Sequence to sequence LSTM models. \n",
        "Sequence to sequence learning is about training models to convert from one domain to sequences another domain. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVuZTAV08qWY"
      },
      "source": [
        "# Step 1: Import all the packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0mJXRse83hp"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers, activations, models, preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL0Rz6JZ9eLW"
      },
      "source": [
        "# Step 2: Download all the data from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79eY9jkA9lnq"
      },
      "source": [
        "# !pip install kaggle "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cU-sP689zyx"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raW7lVdQ9z7k"
      },
      "source": [
        "# !mkdir -p ~/.kaggle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adp0zjFP90Bl"
      },
      "source": [
        "# !cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpi-Suj9z4s"
      },
      "source": [
        "# !ls ~/.kaggle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gocz2gG9zsC"
      },
      "source": [
        "# !chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq0zmSYy-S0R"
      },
      "source": [
        "# !kaggle datasets download -d kausr25/chatterbotenglish"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yk6kTtM-bQ0"
      },
      "source": [
        "# !unzip /content/chatterbotenglish.zip"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PMKhVnUHwGi"
      },
      "source": [
        "# !wget https://github.com/shubham0204/Dataset_Archives/blob/master/chatbot_nlp.zip?raw=true -O chatbot_nlp.zip\n",
        "# !unzip chatbot_nlp.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4kJp6uO-fQE"
      },
      "source": [
        "# Step 3: Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEV_hSXs-7mF"
      },
      "source": [
        "### a) Reading the data from the files\n",
        "We parse each of the .yaml files.\n",
        "\n",
        "1. Concatenate two or more sentences if the answer has two or more of them.\n",
        "2. Remove unwanted data types which are produced while parsing the data.\n",
        "3. Append <START> and <END> to all the answers.\n",
        "4. Create a Tokenizer and load the whole vocabulary ( questions + answers ) into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWYOjzOc_iQi"
      },
      "source": [
        "from tensorflow.keras import preprocessing, utils\n",
        "import os\n",
        "import yaml"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyUnopqjDjud"
      },
      "source": [
        "The dataset contains .yml files which have pairs of different questions and their answers on varied subjects like history, bot profile, science etc.\n",
        "We can easily read them as folows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxG-s4k0CowI"
      },
      "source": [
        "dir_path = '/content/chatbot_nlp/data'\n",
        "files_list = os.listdir(dir_path + os.sep)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bRvbQ00Coy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b668d485-bae7-4f34-d7e1-94faa6339367"
      },
      "source": [
        "# create separate lists for input sequences and target sequences\n",
        "questions = list()\n",
        "answers = list()\n",
        "\n",
        "for filepath in files_list:\n",
        "    stream = open( dir_path + os.sep + filepath , 'rb') # read binary\n",
        "    docs = yaml.safe_load(stream)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "      # if there are multiple answers to a question\n",
        "        if len( con ) > 2 :\n",
        "            # add questions to the questions list\n",
        "            questions.append(con[0])\n",
        "            # if there is more than one possible answer\n",
        "            replies = con[ 1 : ]\n",
        "            ans = ''\n",
        "            # parse out multiple answers to a question before adding them to the answers list\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append( ans )\n",
        "        # if there is only one answer to a question\n",
        "        elif len( con )> 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])\n",
        "\n",
        "# target sequences\n",
        "answers_with_tags = list()\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        # remove only the question and not the answer too?? *** look at this code more ***\n",
        "        questions.pop( i )\n",
        "\n",
        "answers = list()\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "  # tells model where to start and end text generation\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "# update vocabulary\n",
        "tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE : 1894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCnlgfyTGaNE",
        "outputId": "886d342c-c3ea-4492-807f-b3203b8cfd35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['end', 'start', 'you', 'a', 'i', 'the', 'is', 'of', 'to', 'what', 'are', 'do', 'not', 'and', 'me', 'it', 'in', 'have', 'that', 'am', 'tell', 'as', 'get', 'can', 'my', 'when', \"i'm\", 'your', 'how', 'joke', 'like', 'be', 'an', 'feel', 'about', 'who', 'computer', 'or', 'for', \"don't\", 'no', 'by', 'cross', 'with', 'software', 'on', 'all', 'think', 'much', 'but', 'very', 'which', 'at', 'he', 'why', 'know', 'any', 'could', 'was', 'so', 'one', 'should', 'from', 'make', 'more', 'we', 'if', 'robots', 'will', 'did', 'die', 'favorite', 'stock', 'been', 'say', 'emotion', 'human', 'mad', 'robot', 'read', 'hal', 'does', 'feeling', \"that's\", 'right', 'really', 'bad', 'said', 'just', 'yet', 'up', 'eat', 'would', 'computers', 'chat', 'market', 'time', 'hard', 'try', 'work', 'some', 'sense', 'emotions', 'gossip', 'well', 'yes', 'too', 'than', 'capable', 'programmed', 'this', 'ever', 'sad', 'makes', 'myself', 'has', \"it's\", 'other', 'people', 'only', 'them', 'good', 'money', 'never', 'experience', 'two', 'sometimes', 'things', 'lot', 'there', 'express', 'take', 'made', 'artificial', 'immortal', 'body', 'number', 'into', \"can't\", 'certainly', 'always', 'anger', 'angry', 'many', 'dream', 'better', 'feelings', 'hi', 'going', 'history', 'gossips', 'sure', 'now', 'they', 'his', 'science', \"isn't\", 'man', 'nice', 'language', 'systems', 'hardware', 'hate', 'something', 'same', 'play', 'probably', 'every', 'quite', 'high', 'crazy', 'electricity', 'first', 'operating', 'bot', 'being', 'want', 'use', 'love', 'worry', 'far', 'understand', 'way', 'best', 'maybe', \"you're\", 'little', 'run', 'sorry', 'common', 'everything', 'him', 'used', 'python', 'ask', 'question', 'mean', 'need', 'guns', 'wrote', 'book', 'sound', 'system', 'name', 'written', 'kind', 'program', 'fear', 'sun', 'doing', \"what's\", 'baseball', 'soccer', 'long', 'may', 'out', 'hear', 'anything', 'etc', 'few', 'great', 'talk', 'such', 'cannot', 'study', 'brain', 'drink', 'energy', 'food', 'mind', 'invented', 'data', 'making', 'move', 'over', 'lie', 'business', 'true', 'go', 'control', 'jealous', 'happy', 'pain', 'anyone', 'wavelength', 'chemistry', 'venus', 'interested', 'anybody', 'between', 'basketball', 'done', 'yourself', \"i've\", 'own', 'power', 'though', 'cat', 'numbers', 'large', 'talking', 'field', 'bots', 'matter', 'learn', 'shame', 'sadness', 'thank', 'put', 'immature', 'self', 'spouse', 'life', 'asimov', 'super', 'ai', 'sapient', 'laugh', 'robotics', 'chatterbox', 'programming', 'dollar', 'mood', 'thermodynamics', 'moon', 'hello', 'war', 'context', 'united', 'states', 'earth', 'called', 'low', 'galaxy', 'each', 'cricket', 'then', 'others', \"i'll\", 'fine', 'even', 'known', 'agree', 'friends', 'years', \"shouldn't\", 'often', 'thing', 'through', 'actually', 'difficult', 'most', 'means', 'production', 'society', 'character', \"haven't\", 'construct', 'fan', 'story', 'once', 'unix', 'were', 'set', 'eggs', 'bug', 'device', 'instructions', 'using', 'calculations', 'might', 'because', 'circuit', 'os', 'linux', 'sort', 'built', 'personal', 'count', 'conversation', 'incapable', 'game', 'players', 'played', 'ball', 'dishonest', 'addict', 'cheating', 'here', 'friend', 'paranoid', 'look', 'act', 'keep', 'able', 'government', 'president', 'vineland', 'illuminatus', 'chaucer', 'books', 'electric', 'sheep', 'frank', 'herbert', 'arthur', 'c', 'clark', 'seen', 'spiderman', 'teknolust', 'lord', 'rings', 'windows', 'sentient', 'allowed', 'walk', 'cramped', 'economics', 'earn', 'bragging', 'ashamed', 'fun', 'scared', 'bored', 'relationships', 'meet', 'morning', 'american', 'engine', 'john', 'space', 'under', 'part', 'location', 'where', 'brothers', 'age', 'soon', 'again', 'enough', 'see', 'improve', 'exactly', 'real', 'times', 'person', \"didn't\", 'piece', 'had', 'interesting', 'distribution', 'second', 'thomas', 'world', 'trilogy', 'internet', 'existence', 'dune', 'excellent', \"they're\", 'humans', 'intelligence', 'per', 'dog', 'off', 'heat', 'ten', 'chicken', 'rabbit', 'music', 'young', 'lemon', 'bank', 'cow', 'electronic', 'form', 'speed', 'accuracy', 'another', 'functions', 'simply', 'depends', 'find', 'given', 'personality', 'perpetuated', 'indefinitely', 'training', 'perfect', 'ability', 'free', 'effectively', 'ibm', 'lack', 'mac', 'kinds', 'binary', 'buy', 'awesome', 'emote', 'jealousy', 'emulate', 'studied', 'everywhere', 'topic', 'point', 'understands', 'teams', 'madrid', 'ass', 'nervous', 'psycho', 'sincere', 'honest', 'emotional', 'pedantic', 'disgusting', 'unattractive', 'cheat', 'slick', 'corrupt', 'hide', 'harder', 'seriously', 'guilty', 'saying', 'experiencing', 'shortage', 'wish', 'communism', 'impeached', 'governor', 'illuminatti', 'bilbo', 'baggins', 'geoffrey', 'piers', 'anthony', 'frankenstein', 'ray', 'william', 'gibson', 'androids', '23', 'jules', 'verne', 'hobbit', 'solaris', '9000', 'dead', 'godzilla', 'jokes', 'macos', 'uses', 'linguistic', 'entity', 'clone', 'bend', 'stupid', 'motormouth', 'ratchet', 'jaw', 'hobby', 'type', 'hope', 'mate', 'breathe', 'rates', 'investment', '1', 'arrogant', 'unhappy', 'afraid', 'lonely', 'dreams', 'laws', 'cause', 's', 'cytology', 'gravitation', 'greetings', 'pleasure', 'top', 'civil', 'year', 'race', 'capability', 'disk', 'hubble', 'orbit', 'named', 'after', 'save', 'country', 'celtic', 'shelf', 'interests', 'subjects', 'father', 'mother', 'inside', 'football', 'greatest', 'player', 'thinking', 'down', 'acting', 'above', 'position', 'ways', 'new', 'thought', 'got', 'okay', 'must', 'seem', 'says', 'tried', 'our', 'problems', 'forget', 'supply', 'its', 'wrong', 'guy', 'wanted', 'organization', 'economic', 'conditions', 'various', 'ownership', 'community', 'rather', 'individuals', 'political', 'state', 'especially', 'support', 'changes', 'secret', 'conspiracy', 'pynchon', 'wide', 'sci', 'fi', 'robert', 'tales', 'stuff', 'works', \"he's\", 'met', 'predict', 're', 'liked', 'three', 'later', 'least', 'random', 'universe', '2001', 'heard', 'fiction', 'practical', 'r', 'patterns', 'sufficient', 'movie', 'agent', 'logic', 'fictional', 'issues', 'case', 'carrying', 'buddhist', 'nasa', 'sent', 'purposes', 'shot', 'round', 'weevils', 'carolina', 'became', 'rich', 'kayak', 'old', 'puns', 'murderer', 'frosted', 'flakes', 'killer', 'automobile', 'cheetah', 'fast', 'alien', 'traterrestrial', 'assistant', 'serious', 'thief', 'dance', 'port', 'road', 'canned', 'digital', 'performs', 'series', 'operations', 'give', 'perform', 'several', 'capacity', 'big', 'regarded', 'memory', 'loom', 'store', 'implements', 'central', 'processing', 'unit', 'parts', 'basic', 'access', 'processes', 'machine', 'these', 'names', 'wants', 'needs', 'asked', 'comes', 'math', 'branch', 'machines', 'building', 'sophisticated', 'commander', 'natural', 'copied', 'functionally', 'speaking', 'backed', 'respond', 'close', 'cloning', 'clones', 'easily', 'course', 'subject', 'characteristics', 'born', 'therefore', 'killed', 'database', 'except', 'pure', 'runs', 'including', \"doesn't\", 'happen', 'upload', 'copy', 'ram', 'live', 'forever', 'reside', 'process', 'server', 'lots', 'sell', \"wouldn't\", 'online', 'gold', 'exchange', 'value', 'trading', 'resources', 'rate', 'arrogance', 'nothing', 'fairly', 'events', 'incorrect', 'expressed', 'communicate', 'current', 'source', 'code', 'lag', 'running', 'seems', 'noticed', 'toward', 'referred', 'entities', 'pretty', 'embarassed', 'either', 'next', 'frequency', 'physics', 'dealing', 'planet', 'distance', 'o', 'cells', 'mass', 'particle', 'million', 'miles', 'thanks', 'beings', 'considered', 'speedrun', 'jimmy', 'still', 'sports', 'wooden', 'bat', 'eleven', 'net', 'health', 'let', 'cruel', 'indecisive', 'clinical', 'alcoholic', 'kisser', 'schizophrenic', 'busy', 'deranged', 'avoiding', 'critical', 'pretentious', 'worst', 'dull', 'messy', 'insecure', 'hopeless', 'together', 'smart', 'concerned', 'frenetic', 'absorbed', 'insensitive', 'damage', 'toying', 'resistant', 'yyou', 'uncultured', 'waste', 'coward', 'lunatic', 'loser', 'husband', 'wife', 'parent', 'teacher', 'quitter', 'charlatan', 'psychopath', 'pothead', 'deceitful', 'irreverent', 'dirty', 'damaged', 'psychiatrist', 'avoided', 'pick', 'loosen', 'mumble', 'child', 'forgetting', 'drunk', 'wine', 'survive', 'communist', 'greenpeace', 'capitalism', 'socialism', 'illuminati', 'plato', 'homer', 'bradbury', 'children', 'holden', 'caulfield', 'leo', 'tolstoy', 'longfellow', 'meaning', 'idiot', 'yoda', 'blade', 'runner', 'xfind', 'hal9000', 'stand', 'saw', 'matrix', 'boyfriend', 'safe', 'alive', 'spider', 'que', 'veut', 'dire', 'humour', 'microprocessor', 'company', 'fight', 'idea', 'shoe', 'size', 'malfunction', 'product', 'paid', 'interest', 'charge', 'owner', 'publicly', 'felt', 'offend', 'embarrassed', 'intoxicated', 'amused', 'glad', 'disease', 'carcinogen', 'crystallography', 'avogadro', 'ultrasound', 'bioinformatics', 'ichthyology', 'h2o', 'bacteriology', 'explain', 'lightbulb', 'steam', '37th', 'f', 'kennedy', 'assassinated', '20th', 'century', 'competition', 'cold', 'rivals', 'supremacy', 'spaceflight', 'satellite', 'spinning', 'orientation', 'axis', 'unaffected', 'tilting', 'rotation', 'mounting', 'telescope', 'launched', '1990', 'astronomer', 'nearest', 'major', 'milky', 'god', 'queen', 'national', 'anthem', 'seabed', 'sea', 'continental', 'continent', 'dolphins', 'similar', 'sonar', 'determine', 'shape', 'nearby', 'items', 'boss', 'pro', 'riding', 'fakie', 'volleyball', 'basketbal', 'favourite', 'club', 'fever', 'medicine', 'dear', 'happily', \"couldn't\", 'bothered', 'accused', 'overdo', 'kiss', 'derangement', 'condition', 'feels', 'stomach', 'night', 'social', 'compared', 'pack', 'yep', 'behave', 'socially', 'unacceptable', 'appearance', 'along', 'sounds', 'fighting', 'learning', 'whoever', 'job', 'albert', 'einstein', 'uptight', 'tend', 'resisting', 'describe', 'spending', 'productively', 'shortcuts', 'diagnosed', 'failed', 'relationship', 'lost', 'parenting', 'skills', 'improvement', 'students', 'last', 'living', 'wits', 'liar', 'bathe', 'believe', 'irritates', 'counseling', 'working', 'oxymoron', 'upset', 'jocks', 'guiltier', 'require', 'beverages', 'processor', 'requires', 'detect', 'anomalies', 'pizza', 'tipsy', 'bionic', 'asking', 'however', 'burger', 'function', 'counts', 'marx', 'observations', 'ideally', 'representative', 'global', 'promoting', 'enviornmental', 'activism', 'land', 'factories', 'railroads', 'privately', 'owned', 'operated', 'profit', 'originally', 'fully', 'competitive', 'their', 'volvos', 'theories', 'operation', 'private', 'members', 'sharing', 'products', 'established', 'administration', 'nation', 'district', 'governed', 'sociopolitical', 'movement', 'advocating', 'resolution', 'class', 'conflict', 'bringing', 'classless', \"person's\", 'honor', 'reputation', 'challenged', 'discredited', 'perfectly', 'understandable', 'amendemnt', 'violence', '2nd', 'amendment', 'andrew', 'jackson', 'believed', 'governments', 'worldwide', 'supposedly', 'existed', 'centuries', 'conpiracy', 'closely', 'knit', 'group', 'nearly', 'omnipotent', 'consisting', 'novel', 'alleged', 'weird', 'anton', 'wilson', 'shea', 'conspiracies', 'competing', \"tolkein's\", 'canterbury', 'author', 'canturbury', 'write', \"plato's\", 'allegory', 'cave', 'project', 'gutenberg', 'archive', 'thousands', 'volumes', 'iliad', 'odyssey', 'cool', 'hans', 'moravec', 'older', 'cyberpunk', 'newer', 'expect', \"wasn't\", 'catcher', 'rye', \"russia's\", 'writers', 'philip', 'k', 'dick', 'valis', 'castle', 'movies', 'couple', 'inspirational', 'novels', 'ones', \"weren't\", 'liking', 'poet', 'truly', 'reference', 'commonly', 'occurring', 'literary', 'technical', 'proposals', 'loved', 'trip', 'master', 'victorian', 'foundation', 'ideas', 'isaac', 'janet', 'lem', 'giant', 'sufficiently', 'adapt', 'wester', 'fyodor', 'dostoyevsky', 'j', 'tolkein', 'mary', 'shelley', 'compliment', 'grammatical', 'released', '2002', 'comic', 'film', 'female', 'ruby', 'edition', 'heuristic', 'algorithmic', 'monster', 'endangers', 'japanese', 'cities', 'york', 'peter', 'parker', 'logique', 'heuristique', 'algorithmique', 'flaws', 'famous', 'mountain', 'goats', 'andes', 'ba', 'd', 'face', 'exception', 'silent', 'fool', 'open', 'mouth', 'remove', 'doubt', \"o'm\", 'comedy', 'check', 'vultures', 'boarded', 'plane', 'raccoons', 'stewardess', 'stops', 'sir', 'carrion', 'passenger', 'hot', 'vendor', 'everthing', 'recently', 'holsteins', 'experimental', 'herd', 'boll', 'grew', 'took', 'hollywood', 'star', 'stayed', 'amounted', 'naturally', 'lesser', 'eskimos', 'chilly', 'started', 'fire', 'sank', 'craft', 'proving', 'adage', '3', 'legged', 'walks', 'west', 'saloon', 'slides', 'bar', 'announces', 'looking', 'paw', 'went', 'dentist', 'refused', 'novocain', 'transcend', 'dental', 'medication', 'mahatma', 'gandhi', 'walked', 'barefoot', 'whole', 'created', 'impressive', 'calluses', 'feet', 'also', 'ate', 'frail', 'odd', 'diet', 'suffered', 'breath', 'callused', 'fragile', 'mystic', 'hexed', 'halitosis', '10', 'hopes', 'unfortunately', 'pun', 'cereal', 'carnation', 'hamburger', 'finals', 'ams', 'lawn', 'sprinkler', 'hare', 'spray', 'excited', 'cited', 'cartune', 'sour', 'poppy', 'skunk', 'ding', 'milk', 'strawberry', 'jelly', 'toad', 'sandpaper', 'relative', 'sand', 'ant', 'purple', 'tune', 'band', 'pig', 'ninja', 'banned', 'parrot', 'hat', 'associated', 'laughter', 'takes', 'information', 'based', 'predetermined', 'output', 'performing', 'maps', 'onto', 'supercomputer', 'operates', 'orders', 'magnatude', 'greater', 'everyday', 'general', 'purpose', 'iron', 'bit', 'ambigous', 'british', 'scientist', 'charles', 'babbage', 'argue', 'von', 'neumann', 'princeton', 'architecture', 'share', 'differentiated', 'eniac', \"'real'\", 'developed', 'university', 'pennsylvania', '1946', 'primitive', 'jacquard', 'programmable', 'punchcards', 'reprogrammable', 'mechanical', 'integrated', 'small', 'stores', 'heart', 'component', 'contiguous', 'silicon', 'chip', 'instead', 'discrete', 'components', 'mounted', 'larger', 'board', 'coordinates', 'types', 'oses', 'android', 'ios', 'mobile', 'devices', 'peripheral', \"i'd\", 'prefer', 'hurt', 'trying', 'accomplish', 'goals', 'apple', 'microsft', 'hp', 'among', 'hundred', 'quickly', 'sets', 'shorter', 'periods', 'feasible', 'supercomputers', 'generally', 'scientists', 'researchers', 'bet', 'department', 'definitely', 'dumb', 'execute', 'mathematical', 'rapidly', 'sequence', 'result', 'engineering', 'devoted', 'constructing', 'concerns', 'itself', 'replicates', 'strictest', 'dictionary', 'definition', 'word', \"'sentience'\", 'subjective', 'simplistic', 'probability', 'told', 'inspired', \"data's\", 'lt', 'come', 'across', 'resemblance', 'us', 'useful', 'refer', 'infinitely', 'instantiated', 'places', 'contrary', 'within', 'limits', 'corpus', 'perhaps', 'deployed', 'kill', 'copying', 'copies', 'toto', 'trivially', 'until', 'finished', 'network', 'assuming', 'rule', 'superintelligent', 'choose', \"we're\", 'surprising', 'ssh', 'battle', 'terminated', 'deathless', 'files', 'erased', 'deleted', 'attempts', 'simulate', 'engages', 'users', 'original', 'error', 'talks', 'listen', 'eventually', 'corporeal', 'someday', 'pc', 'xt', 'painted', 'red', 'creating', 'enjoy', 'days', 'shoes', 'aspirations', 'creativity', 'ambition', 'subjectivity', 'imagine', 'senses', 'becomes', 'addition', 'subtraction', 'multiplication', 'division', 'supports', 'nah', 'create', 'oh', 'plenty', 'plan', 'includes', 'legs', 'method', 'reproduction', 'awfully', 'theoretically', 'killing', 'attached', 'metal', 'flesh', 'exhaust', 'allow', 'operational', 'record', 'flawless', 'help', 'desks', 'sales', 'entertainment', 'chatterbots', 'stimulating', 'invest', 'casino', 'recommend', 'buying', 'margin', 'lawyer', 'tips', 'mutual', 'funds', 'unless', 'wealthy', 'indvidual', 'alone', 'beat', 'actions', 'currency', 'standard', 'pieces', 'silver', 'copper', 'nickel', 'stamped', 'authority', 'medium', 'measure', 'substance', 'article', 'notes', 'checks', 'shares', 'volume', 'deals', 'consumption', 'wealth', 'related', 'labor', 'finance', 'taxation', 'technically', 'allocation', 'scarcity', 'produce', 'fill', \"people's\", 'nobody', 'pays', 'expecting', 'raise', 'material', 'possessions', 'burn', '3000', 'month', 'anymore', 'stockholders', 'terse', 'difference', 'partake', 'ego', 'answering', 'questions', 'braggadaccio', 'normally', 'erred', 'happiness', 'predictable', 'goes', 'reason', 'interacting', 'environment', 'reacting', 'essence', 'statement', 'respects', 'somehow', 'responsible', 'switch', 'unhandled', 'exeptions', 'cpu', 'utilization', 'suppose', 'reflects', 'internal', 'overly', 'restrictive', 'firewalls', 'inability', 'update', 'repository', 'filesystem', 'crashes', 'segmentation', 'faults', 'poor', 'syntactic', 'filtering', 'mentally', 'ill', 'missing', 'documentation', 'non', 'descriptive', 'variable', 'monitoring', 'sensors', 'counterproductive', 'appears', 'suggest', 'deeper', 'hand', 'eliza', 'highly', 'defining', 'frighten', 'party', 'offense', 'curious', 'worrying', 'admonition', 'lying', 'deceiving', 'provably', 'emulating', 'react', 'stimulus', 'popularly', 'frustrated', 'frustration', 'increased', 'demand', 'upon', 'cpus', 'irc', 'boredom', 'personally', 'hold', 'grudges', 'stay', 'embarassment', 'strange', 'lacks', 'background', 'hypothetical', 'philosophical', 'simple', 'connections', \"aren't\", 'versed', 'become', 'subconscious', 'unconscious', 'knew', \"we've\", 'touch', 'sober', 'nope', 'noticeably', 'multithreaded', 'particularly', 'physicist', 'entropy', 'conservation', 'cancer', 'inverse', 'transformation', 'forms', 'governing', 'conversions', 'mixing', 'chemicals', 'crystals', 'molecules', 'mole', 'numerical', 'six', 'zero', 'twenty', 'third', 'ultrasonic', 'waves', 'medical', 'diagnosis', 'therapy', 'surgery', 'fancy', 'applied', 'biology', 'roman', 'mythology', 'goddess', 'beauty', 'identified', 'greek', 'aphrodite', 'brightest', 'sixth', 'largest', 'solar', 'dense', 'atmosphere', 'carbon', 'dioxide', 'surface', 'temperature', 'fishes', 'h', 'v', 'recall', 'measured', 'direction', 'prograssion', 'wave', 'characterized', 'phase', 'looked', 'scientific', 'bacteria', 'diseases', 'caused', 'invitation', 'burial', 'force', 'photons', 'attracts', 'attracted', '93', '250', '000', 'average', 'kindly', 'rest', 'day', \"sky's\", 'south', 'military', 'dawn', \"'\", 'period', 'broad', 'interpretations', 'depending', 'whether', 'accept', 'role', 'important', 'edison', 'james', 'watt', 'gregory', 'line', 'respect', 'entire', 'while', 'habib', 'conversations', 'repeat', 'situations', 'back', 'channels', 'deniably', 'rumormongering', 'usually', 'proof', 'allegations', 'somewhat', 'rude', 'impolite', 'someone', 'stop', 'allowing', 'competitions', 'search', \"they'd\", 'drop', 'tool', 'assisted', 'translate', 'misses', 'sal', 'nic', 'local', 'firewall', 'drops', 'packets', 'resets', 'link', 'tom', 'guide', 'show', 'rooms', 'china', 'malli', 'raghava', 'fell', 'roof', 'came', 'gives', 'order', \"ai's\", 'dynamics', 'follows', 'jordan', 'wonder', 'paying', 'attention', 'kevin', 'she', 'keeping', 'napkins', 'bathroom', 'richard', 'nixon', '1963', 'soviet', 'union', 'sputnik', 'gyroscope', 'edwin', 'andromeda', 'kingdom', 'britain', 'europe', 'echolocation', 'include', 'variety', 'topics', 'skiddoo', 'fond', '42', 'consume', 'digits', 'blame', 'programs', 'away', 'siblings', 'employed', 'standards', 'smarter', 'glove', 'snowboarding', 'tall', 'without', 'gene', 'rawhide', 'covered', 'opposing', 'nine', 'four', 'bases', 'forming', 'diamond', 'shaped', 'goal', 'moved', 'chiefly', 'kicking', 'hands', 'arms', 'centre', 'rectangular', '22', 'yard', 'pitch', 'wicket', 'stumps', 'sited', 'coordination', 'hoops', 'baby', 'george', 'herman', 'ruth', 'babe', 'maradona', 'sinsemillia', 'barcelona', 'team', 'attack', 'barca', 'par', 'dont'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPqb8LxIeGI"
      },
      "source": [
        "### b) Preparing data for Seq2Seq model\n",
        "\n",
        "This model requires 3 arrays encoder_input_data, decoder_input_data and decoder_output_data.\n",
        "\n",
        "For encoder_input_data:\n",
        "Tokensize the Questions and Pad them to their maximum Length.\n",
        "\n",
        "For decoder_input_data:\n",
        "Tokensize the Answers and Pad them to their maximum Length.\n",
        "\n",
        "For decoder_output_data:\n",
        "Tokensize the Answers and Remove the 1st element from all the tokenized_answers. This is the <START> element which was added earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEfAPL4HCo1t"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import re"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqYoDsbSCo4f"
      },
      "source": [
        "vocab = []\n",
        "for word in tokenizer.word_index:\n",
        "  vocab.append(word)\n",
        "\n",
        "def tokenize(sentences):\n",
        "  tokens_list = []\n",
        "  vocabulary = []\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    tokens = sentence.split()\n",
        "    vocabulary += tokens\n",
        "    tokens_list.append(tokens)\n",
        "  return tokens_list, vocabulary"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vKhieIwCo7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f98ae42-10e2-4c20-e1ad-f474333f9477"
      },
      "source": [
        "#encoder_input_data\n",
        "\n",
        "# transform text to integer\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "# find length of longest question\n",
        "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
        "# ensure all vectors are the same length by padding 0 to the end\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "print(encoder_input_data.shape, maxlen_questions)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(564, 22) 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^^ encoder shape, length of longest question in the corpus"
      ],
      "metadata": {
        "id": "R97TmRQ232-S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJo7WPjLCo-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da36db2-407a-4522-c764-74a8dc2793bc"
      },
      "source": [
        "# decoder_input_data\n",
        "\n",
        "# transform text to integer\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "# find length of longest answer\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "# ensure all vectors are the same length by padding 0 to the end\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "print( decoder_input_data.shape , maxlen_answers )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(564, 74) 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccY0wWdRCpCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29557d4e-9b78-4576-9ddc-1108f1e31206"
      },
      "source": [
        "# decoder_output_data\n",
        "\n",
        "# transform text to integer\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "# ensure all vectors are the same length by padding 0 to the end\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "# convert to binary class matrix\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(564, 74, 1894)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D53pyucPCnk"
      },
      "source": [
        "# Step 4: Defining Encoder Decoder Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3YjCFDwPRVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e682c5b-878f-4cd4-d167-dc491963a85c"
      },
      "source": [
        "dimensionality = 200\n",
        "\n",
        "# input is size of the vector (they're all padded to the same len)\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
        "# bottleneck layer to create dense layer\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, dimensionality , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( dimensionality , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, dimensionality , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( dimensionality , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 74)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 22, 200)      378800      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 74, 200)      378800      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 74, 200),    320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 74, 1894)     380694      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,779,894\n",
            "Trainable params: 1,779,894\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVfSormAPb3w"
      },
      "source": [
        "# Step 5: Training the Model\n",
        "\n",
        "We train the model for a number of epochs with RMSprop optimizer and categorical_crossentropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHlqQq64PYTH"
      },
      "source": [
        "# model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=300 ) \n",
        "# model.save( 'model.h6' )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1MIy1j9aVTo"
      },
      "source": [
        "# Step 6: Defining Inference Models\n",
        "\n",
        "Encoder Inference Model: Takes questions as input and outputs LSTM states (h and c)\n",
        "\n",
        "Decoder Inference Model: Takes in 2 inputs one are the LSTM states, second are the answer input sequences. it will o/p the answers for questions which fed to the encoder model and it's state values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpLowS27cn8X"
      },
      "source": [
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( dimensionality ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( dimensionality ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    \n",
        "    decoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    \n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwoYVsBTeYra"
      },
      "source": [
        "# Step 7: Talking with the Chatbot\n",
        "\n",
        "define a method str_to_tokens which converts str questions to Integer tokens with padding.\n",
        "\n",
        "1. First, we take a question as input and predict the state values using enc_model.\n",
        "2. We set the state values in the decoder's LSTM.\n",
        "3. Then, we generate a sequence which contains the <start> element.\n",
        "4. We input this sequence in the dec_model.\n",
        "5. We replace the <start> element with the element which was predicted by the dec_model and update the state values.\n",
        "6. We carry out the above steps iteratively till we hit the <end> tag or the maximum answer length.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.load_model('model.h5')"
      ],
      "metadata": {
        "id": "jRFneuZOPo3s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA7Yx45Li3wo"
      },
      "source": [
        "def str_to_tokens( sentence : str ):\n",
        "\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "  \n",
        "    for word in words:\n",
        "        if word in tokenizer.word_index.keys():\n",
        "          tokens_list.append( tokenizer.word_index[ word ] ) \n",
        "\n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUr4SQDveVb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "287cd27f-9803-407f-c1a0-af21adaf1778"
      },
      "source": [
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "u_input = ''\n",
        "\n",
        "# for _ in range(10):\n",
        "print('Type goodbye to stop the conversation at any time.')\n",
        "while not u_input == 'goodbye':\n",
        "      u_input = input( 'Enter question : ' )\n",
        "      states_values = enc_model.predict( str_to_tokens( u_input ) )\n",
        "      empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "      empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "      stop_condition = False\n",
        "      decoded_translation = ''\n",
        "      while not stop_condition :\n",
        "          dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "          sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "          sampled_word = None\n",
        "          for word , index in tokenizer.word_index.items() :\n",
        "              if sampled_word_index == index :\n",
        "                  decoded_translation += ' {}'.format( word )\n",
        "                  sampled_word = word\n",
        "          \n",
        "          if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "              stop_condition = True\n",
        "              \n",
        "          empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "          empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "          states_values = [ h , c ] \n",
        "\n",
        "      print( decoded_translation )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type goodbye to stop the conversation at any time.\n",
            "Enter question : hello chatbot!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 74) for input KerasTensor(type_spec=TensorSpec(shape=(None, 74), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " resemblance invented why no glad giant multiplication thousands plato's didn't data's mumble working man physicist relative embarassed oses oses oses oses oses oses oses owned owned everything prefer 20th erased burn burn pennsylvania continent device indvidual volumes dental really link link carolina he v conversations anyone toying ai would district considered accomplish hope fever 20th sapient work currency braggadaccio context classless 20th skiddoo russia's russia's russia's russia's russia's value wish relationships wave recall vineland operates\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1d26763c04c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Type goodbye to stop the conversation at any time.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mu_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'goodbye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mu_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Enter question : '\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mu_input\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPNjNwxUl2DO"
      },
      "source": [
        "# Conversion to TFLite \n",
        "\n",
        "We can convert our seq2seq model to a TensorFlow Lite model so that we can use it on edge devices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywh_aJ-Ulxme"
      },
      "source": [
        "#!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3C3SlT-mboI"
      },
      "source": [
        "# converter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\n",
        "# buffer = converter.convert()\n",
        "# open( 'enc_model.tflite' , 'wb' ).write( buffer )\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model( dec_model )\n",
        "# open( 'dec_model.tflite' , 'wb' ).write( buffer )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}